{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1cf2c6-d6d6-4d7f-9ec1-051b372053fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV & pre-filtering locally ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_7008\\1282397712.py:115: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"priority\"] = df[\"Name\"].str.contains(title_re, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Candidate QIDs to check: 1,200,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching:  19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                | 4481/24000 [1:55:55<9:49:55,  1.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Batch failed (attempt 1/3): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24000/24000 [10:36:01<00:00,  1.59s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Collected 2,182 high-quality polymaths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [03:27<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ  Saved 2,182 polymaths ‚Üí polymaths_enriched.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import aiohttp, asyncio, json, re, random, time\n",
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ---------- USER SETTINGS ----------\n",
    "CSV_PATH        = \"Downloads/AgeDataset-V1.csv\"\n",
    "TARGET_POLYS    = 100_000\n",
    "BATCH_SIZE      = 50\n",
    "MAX_CONCURRENT  = 5\n",
    "CANDIDATE_CAP   = 1_200_000\n",
    "MIN_BIRTH_YEAR  = -1000\n",
    "MAX_BIRTH_YEAR  = 2022\n",
    "POLYMATH_THRESH = 3\n",
    "JSON_OUT        = \"polymaths_enriched.json\"\n",
    "RANDOM_SEED     = 42\n",
    "# ------------------------------------\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "bucket_map = {\n",
    "    # --- STEM ---\n",
    "    \"Q901\": \"STEM\",              # scientist\n",
    "    \"Q170790\": \"STEM\",           # mathematician\n",
    "    \"Q169470\": \"STEM\",           # physicist\n",
    "    \"Q593644\": \"STEM\",           # chemist\n",
    "    \"Q81096\": \"STEM\",            # engineer\n",
    "    \"Q39631\": \"STEM\",            # physician\n",
    "    \"Q11063\": \"STEM\",            # astronomer\n",
    "    \"Q19350898\": \"STEM\",         # theoretical physicist\n",
    "    \"Q82594\": \"STEM\",            # computer scientist\n",
    "    \"Q2732142\": \"STEM\",          # statistician\n",
    "    \"Q2919046\": \"STEM\",          # biochemist\n",
    "    \"Q6337803\": \"STEM\",          # neuroscientist\n",
    "    \"Q29169143\": \"STEM\",         # data scientist\n",
    "    \"Q520549\": \"STEM\",           # geologist\n",
    "    \"Q350979\": \"STEM\",           # zoologist\n",
    "    \"Q2374149\": \"STEM\",          # botanist\n",
    "    \"Q2310145\": \"STEM\",          # meteorologist\n",
    "    \"Q205375\": \"STEM\",           # inventor\n",
    "    \"Q2055046\": \"STEM\",          # physiologist\n",
    "    \"Q18805\": \"STEM\",            # naturalist\n",
    "\n",
    "    # --- Humanities ---\n",
    "    \"Q4964182\": \"Humanities\",    # philosopher\n",
    "    \"Q201788\": \"Humanities\",     # historian\n",
    "    \"Q1622272\": \"Humanities\",    # university teacher\n",
    "    \"Q16533\": \"Humanities\",      # judge\n",
    "    \"Q188094\": \"Humanities\",     # economist\n",
    "    \"Q82955\": \"Humanities\",      # politician (intellectuals)\n",
    "    \"Q37226\": \"Humanities\",      # teacher\n",
    "    \"Q2306091\": \"Humanities\",    # sociologist\n",
    "    \"Q15632482\": \"Humanities\",   # epistemologist\n",
    "    \"Q1234713\": \"Humanities\",    # theologian\n",
    "    \"Q4773904\": \"Humanities\",    # anthropologist\n",
    "    \"Q14467526\": \"Humanities\",   # linguist\n",
    "    \"Q14565331\": \"Humanities\",   # logician\n",
    "    \"Q2468727\": \"Humanities\",    # classicist\n",
    "\n",
    "    # --- Arts ---\n",
    "    \"Q1028181\": \"Arts\",          # painter\n",
    "    \"Q36834\": \"Arts\",            # composer\n",
    "    \"Q36180\": \"Arts\",            # writer\n",
    "    \"Q49757\": \"Arts\",            # poet\n",
    "    \"Q42973\": \"Arts\",            # architect\n",
    "    \"Q214917\": \"Arts\",           # playwright\n",
    "    \"Q639669\": \"Arts\",           # musician\n",
    "    \"Q3303330\": \"Arts\",          # calligrapher\n",
    "    \"Q6625963\": \"Arts\",          # novelist\n",
    "    \"Q11774202\": \"Arts\",         # essayist\n",
    "    \"Q8178443\": \"Arts\",          # librettist\n",
    "    \"Q1281618\": \"Arts\",          # sculptor\n",
    "    \"Q11569986\": \"Arts\",         # printmaker\n",
    "    \"Q3658608\": \"Arts\",          # caricaturist\n",
    "    \"Q3391743\": \"Arts\",          # visual artist\n",
    "    \"Q5322166\": \"Arts\",          # designer\n",
    "    \"Q10774753\": \"Arts\",         # performance artist\n",
    "\n",
    "    # --- Filtering Domains ---\n",
    "    \"Q4991371\": \"Military\",      # soldier\n",
    "    \"Q11545923\": \"Military\",     # military commander\n",
    "    \"Q116\": \"Royalty\",           # monarch\n",
    "    \"Q14828907\": \"Politics\",     # dictator\n",
    "    \"Q121998\": \"Politics\",       # ambassador (tentative)\n",
    "}\n",
    "\n",
    "good_domains = {\"STEM\", \"Arts\", \"Humanities\"}\n",
    "power_domains = {\"Politics\", \"Military\", \"Royalty\"}\n",
    "\n",
    "def domains_for(occ_ids):\n",
    "    return {bucket_map.get(qid, \"Other\") for qid in occ_ids}\n",
    "\n",
    "def is_real_polymath(occ_ids):\n",
    "    doms = domains_for(occ_ids)\n",
    "    good_doms = doms & good_domains\n",
    "\n",
    "    # Must span at least 3 distinct domains\n",
    "    if len(good_doms) < 3:\n",
    "        return False\n",
    "    # Must have at least one occupation per domain\n",
    "    if len(set(bucket_map.get(q, \"Other\") for q in occ_ids if bucket_map.get(q) in good_domains)) < 3:\n",
    "        return False\n",
    "    # Must have at least POLYMATH_THRESH occupations total\n",
    "    if len(occ_ids) < POLYMATH_THRESH:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "print(\"Loading CSV & pre-filtering locally ‚Ä¶\")\n",
    "df = pd.read_csv(CSV_PATH, usecols=[\"Id\", \"Name\", \"Birth year\"], dtype=str)\n",
    "df[\"Birth year\"] = pd.to_numeric(df[\"Birth year\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Id\", \"Birth year\"])\n",
    "df = df[(df[\"Birth year\"] >= MIN_BIRTH_YEAR) & (df[\"Birth year\"] <= MAX_BIRTH_YEAR)]\n",
    "title_re = re.compile(r\"\\\\b(Dr|Prof|Sir|al-)\\\\b\", re.I)\n",
    "df[\"priority\"] = df[\"Name\"].str.contains(title_re, na=False)\n",
    "df = df.sort_values(\"priority\", ascending=False).sample(frac=1.0, random_state=RANDOM_SEED)\n",
    "candidates = df.head(CANDIDATE_CAP)[\"Id\"].tolist()\n",
    "print(f\"‚Üí Candidate QIDs to check: {len(candidates):,}\")\n",
    "\n",
    "API = (\"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&ids=\")\n",
    "\n",
    "sem = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "polymaths = []\n",
    "seen = set()\n",
    "\n",
    "def extract_date(claims, prop):\n",
    "    try:\n",
    "        raw = claims[prop][0]['mainsnak']['datavalue']['value']['time']\n",
    "        year_str = raw.strip('+').split('-')[0]\n",
    "        return int(year_str) if year_str.isdigit() or (year_str.startswith('-') and year_str[1:].isdigit()) else None\n",
    "    except (KeyError, IndexError, TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "def get_all_ids(claims, prop):\n",
    "    try:\n",
    "        return [c['mainsnak']['datavalue']['value']['id']\n",
    "                for c in claims[prop] if 'datavalue' in c['mainsnak']]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "async def fetch(session, qids, retries=3):\n",
    "    url = API + \"|\".join(qids)\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with sem:\n",
    "                async with session.get(url, timeout=aiohttp.ClientTimeout(total=60)) as r:\n",
    "                    return await r.json()\n",
    "        except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n",
    "            print(f\"[Warning] Batch failed (attempt {attempt+1}/{retries}): {e}\")\n",
    "            await asyncio.sleep(1)\n",
    "    print(f\"[Error] Failed after {retries} retries: {qids}\")\n",
    "    return {\"entities\": {}}\n",
    "\n",
    "\n",
    "async def pipeline(qids):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in tqdm(range(0, len(qids), BATCH_SIZE), desc=\"Fetching\", unit=\"batch\"):\n",
    "            if len(polymaths) >= TARGET_POLYS:\n",
    "                break\n",
    "            batch = qids[i:i+BATCH_SIZE]\n",
    "            data = await fetch(session, batch)\n",
    "            for qid, ent in data[\"entities\"].items():\n",
    "                if qid in seen:\n",
    "                    continue\n",
    "                seen.add(qid)\n",
    "                claims = ent.get(\"claims\", {})\n",
    "                occ_ids = get_all_ids(claims, \"P106\")\n",
    "                if is_real_polymath(occ_ids):\n",
    "                    polymaths.append({\n",
    "                        \"qid\": qid,\n",
    "                        \"occ_ids\": sorted(occ_ids),\n",
    "                        \"polymath_score\": len(occ_ids),\n",
    "                        \"birth_year\": extract_date(claims, \"P569\"),\n",
    "                        \"death_year\": extract_date(claims, \"P570\"),\n",
    "                        \"place_of_birth\": get_all_ids(claims, \"P19\"),\n",
    "                        \"citizenship\": get_all_ids(claims, \"P27\"),\n",
    "                        \"gender\": get_all_ids(claims, \"P21\"),\n",
    "                        \"educated_at\": get_all_ids(claims, \"P69\"),\n",
    "                        \"notable_works\": get_all_ids(claims, \"P800\"),\n",
    "                        \"influenced_by\": get_all_ids(claims, \"P737\"),\n",
    "                        \"influenced\": get_all_ids(claims, \"P737\"),\n",
    "                        \"fields_of_work\": get_all_ids(claims, \"P101\"),\n",
    "                        \"awards\": get_all_ids(claims, \"P166\"),\n",
    "                        \"member_of\": get_all_ids(claims, \"P463\"),\n",
    "                        \"languages\": get_all_ids(claims, \"P407\"),\n",
    "                        \"cause_of_death\": get_all_ids(claims, \"P509\"),\n",
    "                    })\n",
    "            await asyncio.sleep(0.2)\n",
    "\n",
    "async def label_lookup(qids):\n",
    "    url = (\"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=labels&languages=en&ids=\" + \"|\".join(qids))\n",
    "    async with aiohttp.ClientSession() as s:\n",
    "        async with s.get(url, timeout=40) as r:\n",
    "            data = await r.json()\n",
    "            return {qid: d.get(\"labels\", {}).get(\"en\", {}).get(\"value\", qid)\n",
    "                    for qid, d in data[\"entities\"].items()}\n",
    "\n",
    "def chunked(seq, n):\n",
    "    for k in range(0, len(seq), n):\n",
    "        yield seq[k:k+n]\n",
    "\n",
    "async def enrich_labels(rows):\n",
    "    qid_pool = set()\n",
    "    for row in rows:\n",
    "        qid_pool.add(row[\"qid\"])\n",
    "        for k, v in row.items():\n",
    "            if isinstance(v, list):\n",
    "                qid_pool.update(v)\n",
    "\n",
    "    label_map = {}\n",
    "    for ids in tqdm(list(chunked(sorted(qid_pool), 50)), desc=\"Label batches\"):\n",
    "        label_map.update(await label_lookup(ids))\n",
    "        await asyncio.sleep(0.2)\n",
    "\n",
    "    for row in rows:\n",
    "        row[\"name\"] = label_map.get(row[\"qid\"], row[\"qid\"])\n",
    "        row[\"occupations\"] = [label_map.get(o, o) for o in row.pop(\"occ_ids\")]\n",
    "        for field in [\"place_of_birth\", \"citizenship\", \"gender\", \"educated_at\",\n",
    "                      \"notable_works\", \"influenced_by\", \"influenced\",\n",
    "                      \"fields_of_work\", \"awards\", \"member_of\",\n",
    "                      \"languages\", \"cause_of_death\"]:\n",
    "            row[field] = [label_map.get(q, q) for q in row.get(field, [])]\n",
    "\n",
    "# Run everything\n",
    "asyncio.run(pipeline(candidates))\n",
    "print(f\"‚úì Collected {len(polymaths):,} high-quality polymaths\")\n",
    "\n",
    "asyncio.run(enrich_labels(polymaths))\n",
    "\n",
    "with open(JSON_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(polymaths, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(polymaths):,} polymaths ‚Üí {JSON_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57078e7-d897-435b-8cf5-59130fbd1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched JSON\n",
    "with open(\"polymaths_enriched.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Label-based bucket map (lowercased for matching)\n",
    "label_map = {\n",
    "    # STEM\n",
    "    \"scientist\": \"STEM\", \"mathematician\": \"STEM\", \"physicist\": \"STEM\", \"chemist\": \"STEM\",\n",
    "    \"engineer\": \"STEM\", \"physician\": \"STEM\", \"astronomer\": \"STEM\", \"theoretical physicist\": \"STEM\",\n",
    "    \"computer scientist\": \"STEM\", \"statistician\": \"STEM\", \"biochemist\": \"STEM\", \"neuroscientist\": \"STEM\",\n",
    "    \"data scientist\": \"STEM\", \"geologist\": \"STEM\", \"zoologist\": \"STEM\", \"botanist\": \"STEM\",\n",
    "    \"meteorologist\": \"STEM\", \"inventor\": \"STEM\", \"physiologist\": \"STEM\", \"naturalist\": \"STEM\",\n",
    "\n",
    "    # Humanities\n",
    "    \"philosopher\": \"Humanities\", \"historian\": \"Humanities\", \"university teacher\": \"Humanities\",\n",
    "    \"judge\": \"Humanities\", \"economist\": \"Humanities\", \"politician\": \"Humanities\", \"teacher\": \"Humanities\",\n",
    "    \"sociologist\": \"Humanities\", \"epistemologist\": \"Humanities\", \"theologian\": \"Humanities\",\n",
    "    \"cultural theorist\": \"Humanities\", \"anthropologist\": \"Humanities\", \"linguist\": \"Humanities\",\n",
    "    \"logician\": \"Humanities\", \"classicist\": \"Humanities\",\n",
    "\n",
    "    # Arts\n",
    "    \"painter\": \"Arts\", \"composer\": \"Arts\", \"writer\": \"Arts\", \"poet\": \"Arts\", \"architect\": \"Arts\",\n",
    "    \"playwright\": \"Arts\", \"musician\": \"Arts\", \"calligrapher\": \"Arts\", \"novelist\": \"Arts\", \"essayist\": \"Arts\",\n",
    "    \"librettist\": \"Arts\", \"sculptor\": \"Arts\", \"printmaker\": \"Arts\", \"caricaturist\": \"Arts\",\n",
    "    \"visual artist\": \"Arts\", \"designer\": \"Arts\", \"performance artist\": \"Arts\",\n",
    "}\n",
    "\n",
    "good_domains = {\"STEM\", \"Arts\", \"Humanities\"}\n",
    "\n",
    "def is_valid_polymath_by_label(occupations):\n",
    "    cleaned = [label.lower() for label in occupations]\n",
    "    valid_labels = [label for label in cleaned if label in label_map]\n",
    "    domains = {label_map[label] for label in valid_labels}\n",
    "    return len(valid_labels) >= 3 and len(domains & good_domains) >= 3\n",
    "\n",
    "# Apply to dataset\n",
    "for row in data:\n",
    "    occ_labels = row.get(\"occupations\", [])\n",
    "    cleaned = [label.lower() for label in occ_labels]\n",
    "    valid_labels = [label for label in cleaned if label in label_map]\n",
    "    row[\"polymath_score_mapped\"] = len(valid_labels)\n",
    "    row[\"valid_polymath\"] = is_valid_polymath_by_label(occ_labels)\n",
    "\n",
    "# Save\n",
    "with open(\"polymaths_enriched_updated.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Label-based scoring done and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
